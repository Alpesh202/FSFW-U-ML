{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0a4a2e90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataframe\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Data Scaler and labelencoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Data Split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# ML model\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from sklearn.multiclass import OneVsOneClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "import tensorflow as tf \n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense \n",
    "from tensorflow.keras.layers import Dropout\n",
    "# from scikeras.wrappers import KerasClassifier # if it is showing this error then try to import this library\n",
    "# from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "\n",
    "# Evaluation of the model\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# Do load and unload the model\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af7659dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the data path\n",
    "raw_data = r'C:\\Users\\Alpesh\\Desktop\\RawData\\Urine.xlsx'\n",
    "df = pd.read_excel(raw_data)\n",
    "\n",
    "# Encoding the categorial column into numerical value\n",
    "label_dict = {'NU': 0,\n",
    "              'CC': 1,\n",
    "              'ECG': 2,\n",
    "              'HTP': 3,\n",
    "              'NRT': 4,\n",
    "              'OT': 5}\n",
    "\n",
    "df['Group_encoded'] = df['Group'].map(label_dict)\n",
    "df.head()\n",
    "df.tail()\n",
    "\n",
    "# Split the data into features (X) and target variable (y)\n",
    "X = df.drop(['Group', 'Group_encoded'], axis=1)\n",
    "y = df['Group_encoded']\n",
    "\n",
    "# View the dataset\n",
    "X.head()\n",
    "y.head()\n",
    "print(X.shape)\n",
    "print(y.shape)\n",
    "\n",
    "# Split the data into training and testing sets in stratified way\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, shuffle=True, random_state=42, stratify=y)\n",
    "\n",
    "# Check the splitted data\n",
    "print(f'X_train.shape: {X_train.shape}')\n",
    "print(f'y_train.shape: {y_train.shape}')\n",
    "print(f'X_test.shape: {X_test.shape}')\n",
    "print(f'y_test.shape: {y_test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b728b18c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing Classifiers\n",
    "rf_model = RandomForestClassifier(random_state=42)\n",
    "dt_model = DecisionTreeClassifier(random_state=42)\n",
    "xgb_model = GradientBoostingClassifier()\n",
    "knn_model = KNeighborsClassifier()\n",
    "svm_model = OneVsOneClassifier(SVC())\n",
    "\n",
    "# Create a function to build the Keras model\n",
    "def create_model(layers=1, units=64, activation='relu', alpha=0.0001, dropout_rate=0.2, learning_rate=0.001):\n",
    "    model = Sequential()\n",
    "    for _ in range(layers):\n",
    "        model.add(Dense(units, activation=activation, kernel_regularizer=tf.keras.regularizers.l2(alpha)))\n",
    "        model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(len(np.unique(y)), activation='softmax'))  # Assuming 'Group_encoded' is a categorical variable\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "    model.compile(loss='sparse_categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Create a KerasClassifier\n",
    "mlp_model = tf.keras.wrappers.scikit_learn.KerasClassifier(build_fn=create_model, verbose=0)\n",
    "\n",
    "# Building the pipelines\n",
    "knn_model_std = Pipeline([('std', StandardScaler()),\n",
    "                  ('knn_model', knn_model)])\n",
    "\n",
    "svm_model_std = Pipeline([('std', StandardScaler()),\n",
    "                  ('svm_model', svm_model)])\n",
    "\n",
    "mlp_model_std = Pipeline([('std', StandardScaler()),\n",
    "                  ('mlp_model', mlp_model)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "eef73fa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up the parameter grids\n",
    "\n",
    "param_grid_rf = {\n",
    "    'n_estimators': [100, 200, 300, 500, 1000], # NL2, NL5 Optimised\n",
    "    'max_depth': [None, 2, 3, 4, 5, 10], # NL2 Optimised\n",
    "    'min_samples_split': [2, 3, 5, 10, 15], # Optimised\n",
    "    'min_samples_leaf': [1, 2, 3, 5, 10], # NL5 Optimised\n",
    "    'max_features': ['auto', 'sqrt', 'log2', 0.2, 0.5], # NL5 Optimised\n",
    "    'max_leaf_nodes': [None, 10, 20, 30, 40, 50]} # Optimised\n",
    "\n",
    "param_grid_dt = {\n",
    "    'max_depth': [5, 10, 20, 30], # NL2, NL4 Optimised\n",
    "    'min_samples_split': [2, 3, 5, 10, 15], # Optimised\n",
    "    'min_samples_leaf': [1, 2, 4], # NL4 Optimised\n",
    "    'max_features': ['auto', 'sqrt', 'log2', 0.2, 0.5], # Optimised\n",
    "    'max_leaf_nodes': [None, 10, 20, 30, 40, 50]}\n",
    "\n",
    "param_grid_xgb = {\n",
    "    'min_samples_split': [3],\n",
    "    'min_samples_leaf': [1, 2, 5],\n",
    "    'subsample': [0.8, 1.0],\n",
    "    'max_features': ['auto', 'sqrt', 'log2']}\n",
    "\n",
    "param_grid_knn = {\n",
    "    'knn_model__n_neighbors': [10],\n",
    "    'knn_model__weights': ['distance'],\n",
    "    'knn_model__algorithm': ['auto'],\n",
    "    'knn_model__leaf_size': [20],\n",
    "    'knn_model__p': [2],\n",
    "    'knn_model__metric': ['manhattan']}\n",
    "\n",
    "param_grid_svm = [\n",
    "    {'svm_model__estimator__kernel': ['rbf'],\n",
    "     'svm_model__estimator__C': [1.0],\n",
    "     'svm_model__estimator__gamma': [0.001]},\n",
    "    {'svm_model__estimator__kernel': ['linear'],\n",
    "     'svm_model__estimator__C': [1.0]}]\n",
    "\n",
    "param_grid_mlp = {\n",
    "    'mlp_model__layers': [2],\n",
    "    'mlp_model__units': [64],\n",
    "    'mlp_model__activation': ['relu'],\n",
    "    'mlp_model__alpha': [0.001],\n",
    "    'mlp_model__dropout_rate': [0.4],\n",
    "    'mlp_model__learning_rate': [0.01],\n",
    "    'mlp_model__batch_size': [16],\n",
    "    'mlp_model__epochs': [100]}\n",
    "\n",
    "# Create a list of classifiers, corresponding parameter grids and classifier short name\n",
    "classifiers = [rf_model, dt_model]\n",
    "param_grids = [param_grid_rf, param_grid_dt]\n",
    "name = ['RForest', 'DTree']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d816ca83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------- \n",
      "\n",
      "Algorithm: DTree\n",
      "    Inner loop:\n",
      "\n",
      "        Best ACC (avg. of inner test folds) 76.85%\n",
      "        Best parameters: {'max_depth': 5, 'max_features': 'auto', 'max_leaf_nodes': None, 'min_samples_leaf': 4, 'min_samples_split': 2}\n",
      "        ACC (on outer test fold) 59.26%\n",
      "\n",
      "        Best ACC (avg. of inner test folds) 87.04%\n",
      "        Best parameters: {'max_depth': 10, 'max_features': 0.5, 'max_leaf_nodes': None, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "        ACC (on outer test fold) 85.19%\n",
      "\n",
      "        Best ACC (avg. of inner test folds) 80.56%\n",
      "        Best parameters: {'max_depth': 10, 'max_features': 0.5, 'max_leaf_nodes': None, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "        ACC (on outer test fold) 85.19%\n",
      "\n",
      "        Best ACC (avg. of inner test folds) 79.63%\n",
      "        Best parameters: {'max_depth': 5, 'max_features': 0.2, 'max_leaf_nodes': None, 'min_samples_leaf': 1, 'min_samples_split': 10}\n",
      "        ACC (on outer test fold) 70.37%\n",
      "\n",
      "        Best ACC (avg. of inner test folds) 80.56%\n",
      "        Best parameters: {'max_depth': 10, 'max_features': 0.2, 'max_leaf_nodes': None, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "        ACC (on outer test fold) 88.89%\n",
      "\n",
      "    Outer Loop:\n",
      "        ACC 59.26%\n",
      "        ACC 85.19%\n",
      "        ACC 85.19%\n",
      "        ACC 70.37%\n",
      "        ACC 88.89%\n",
      "\n",
      "DTree | outer ACC 77.78% +/- 11.23\n",
      "-------------------------------------------------- \n",
      "\n",
      "Algorithm: RForest\n",
      "    Inner loop:\n"
     ]
    }
   ],
   "source": [
    "# Setting up GridSearchCV objects\n",
    "\n",
    "gridcvs = {}\n",
    "inner_cv = StratifiedKFold(n_splits=2, shuffle=True, random_state=1)\n",
    "\n",
    "for model, param_grid, name in zip(classifiers, param_grids, name):\n",
    "    gcv = GridSearchCV(estimator=model,\n",
    "                       param_grid=param_grid,\n",
    "                       scoring='accuracy',\n",
    "                       n_jobs=-1,\n",
    "                       cv=inner_cv,\n",
    "                       verbose=0,\n",
    "                       refit=True)\n",
    "    gridcvs[name] = gcv\n",
    "    \n",
    "# Outer cross-validation loop\n",
    "outer_cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=1)\n",
    "\n",
    "for name, gs_est in sorted(gridcvs.items()):\n",
    "    print(50 * '-', '\\n')\n",
    "    print(f'Algorithm: {name}')\n",
    "    print('    Inner loop:')\n",
    "\n",
    "    # Inner cross-validation loop\n",
    "    for i, (train_index, test_index) in enumerate(outer_cv.split(X_train, y_train), 1):\n",
    "        X_train_inner, X_test_inner = X_train.iloc[train_index], X_train.iloc[test_index]\n",
    "        y_train_inner, y_test_inner = y_train.iloc[train_index], y_train.iloc[test_index]\n",
    "\n",
    "        gs_est.fit(X_train_inner, y_train_inner)\n",
    "\n",
    "        # Assuming `gs_est.best_params_` and `gs_est.best_score_` are accessible\n",
    "        print(f'\\n        Best ACC (avg. of inner test folds) {gs_est.best_score_ * 100:.2f}%')\n",
    "        print(f'        Best parameters: {gs_est.best_params_}')\n",
    "        \n",
    "        # Assuming you have a function or code to calculate ACC for the outer test fold\n",
    "        acc_outer = gs_est.score(X_test_inner, y_test_inner)\n",
    "        print(f'        ACC (on outer test fold) {acc_outer * 100:.2f}%')\n",
    "\n",
    "    # Outer cross-validation loop\n",
    "    nested_scores = cross_val_score(gs_est, X_train, y_train, cv=outer_cv, scoring='accuracy')\n",
    "    \n",
    "    print('\\n    Outer Loop:')\n",
    "    for i, score in enumerate(nested_scores, 1):\n",
    "        print(f'        ACC {score * 100:.2f}%')\n",
    "\n",
    "    print(f'\\n{name} | outer ACC {nested_scores.mean() * 100:.2f}% +/- {nested_scores.std() * 100:.2f}')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28ea1579",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
