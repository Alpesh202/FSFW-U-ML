{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Alpesh202/FSFW-U-ML/blob/main/Untitled0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W5rYTm6FQwag"
      },
      "source": [
        "## Install the necessary package\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "UX7mJzKEIH40",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c1713b88-bae5-4973-b75c-d7bea28d08b8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.2.2)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.15.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (1.5.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.23.5)\n",
            "Requirement already satisfied: openpyxl in /usr/local/lib/python3.10/dist-packages (3.1.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.7.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (1.3.2)\n",
            "Collecting scikeras\n",
            "  Downloading scikeras-0.12.0-py3-none-any.whl (27 kB)\n",
            "Requirement already satisfied: mlxtend in /usr/local/lib/python3.10/dist-packages (0.22.0)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.11.4)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.2.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (23.5.26)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.5.4)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.9.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (16.0.6)\n",
            "Requirement already satisfied: ml-dtypes~=0.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (23.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.5.0)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.35.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.60.0)\n",
            "Requirement already satisfied: tensorboard<2.16,>=2.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.1)\n",
            "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.0)\n",
            "Requirement already satisfied: keras<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2023.3.post1)\n",
            "Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.10/dist-packages (from openpyxl) (1.1.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.47.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.5)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.1.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.42.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.17.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (1.2.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.5.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.31.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.0.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (5.3.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2023.11.17)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow) (2.1.3)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.5.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (3.2.2)\n",
            "Installing collected packages: scikeras\n",
            "Successfully installed scikeras-0.12.0\n"
          ]
        }
      ],
      "source": [
        "!pip install scikit-learn tensorflow pandas numpy openpyxl matplotlib joblib scikeras mlxtend"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eLi-WyFPSRDC"
      },
      "source": [
        "## Install the necessary library"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "MoqM4xLrR4kn"
      },
      "outputs": [],
      "source": [
        "# Data Handling\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Data Preprocessing\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import StratifiedKFold, GridSearchCV, train_test_split, cross_val_score\n",
        "\n",
        "# Machine Learning Models\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "\n",
        "# multiclass classification problem using an artificial neural network in Python\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from scikeras.wrappers import KerasClassifier\n",
        "\n",
        "# Model Evaluation\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix, precision_score, recall_score, f1_score\n",
        "\n",
        "# Model Persistence - load and unload the model\n",
        "import joblib"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E1OBkTsyS5XP"
      },
      "source": [
        "## Data handling and preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = \"/content/Urine.xlsx\"\n",
        "\n",
        "# Read the Excel file into a Pandas DataFrame\n",
        "df = pd.read_excel(file_path)\n",
        "\n",
        "# Display the DataFrame\n",
        "print(df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0TnUgYNPadDf",
        "outputId": "9b2c1f05-c484-4a32-8730-2158652d927b"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    Group  HIPI_2.336_94.05351_CC_Spe  RPPI_1.43_96.06918_CC+HTP+OT_Spe  \\\n",
            "0      NU                1.019047e+06                      4.369687e+06   \n",
            "1      NU                1.251668e+06                      3.461698e+06   \n",
            "2      NU                1.826197e+06                      4.281905e+06   \n",
            "3      NU                6.082321e+05                      1.511828e+07   \n",
            "4      NU                2.545110e+06                      3.993454e+06   \n",
            "..    ...                         ...                               ...   \n",
            "175    OT                4.313545e+06                      3.042152e+07   \n",
            "176    OT                2.890789e+06                      2.167816e+07   \n",
            "177    OT                2.406921e+06                      7.114720e+07   \n",
            "178    OT                1.670501e+06                      2.404034e+07   \n",
            "179    OT                1.414180e+06                      1.774169e+07   \n",
            "\n",
            "     HIPI_2.265_98.04838_CC_Spe  RPPI_2.289_100.10043_CC_Spe  \\\n",
            "0                  7.889221e+05                 4.770424e+06   \n",
            "1                  1.856294e+06                 1.086797e+07   \n",
            "2                  3.991539e+05                 9.550689e+06   \n",
            "3                  1.054087e+06                 4.636457e+06   \n",
            "4                  1.751294e+06                 8.623506e+06   \n",
            "..                          ...                          ...   \n",
            "175                2.044967e+06                 3.975717e+06   \n",
            "176                1.923326e+06                 2.261343e+06   \n",
            "177                1.338000e+06                 1.469235e+07   \n",
            "178                2.065914e+06                 6.567565e+06   \n",
            "179                2.289026e+06                 1.468933e+07   \n",
            "\n",
            "     RPPI_1.153_101.08446_NM  HIPI_5.959_105.05821_CC_Spe  \\\n",
            "0               2.462451e+07                 7.052467e+05   \n",
            "1               2.820727e+07                 3.188988e+05   \n",
            "2               2.726626e+07                 3.819677e+05   \n",
            "3               2.287667e+07                 6.618804e+06   \n",
            "4               1.163009e+07                 9.938222e+05   \n",
            "..                       ...                          ...   \n",
            "175             8.506748e+08                 1.036018e+06   \n",
            "176             9.130817e+08                 1.173640e+06   \n",
            "177             2.064160e+08                 2.195894e+06   \n",
            "178             4.851716e+08                 2.112602e+06   \n",
            "179             3.900040e+08                 1.275847e+06   \n",
            "\n",
            "     RPPI_6.564_108.05787_OT_Spe  HIPI_1.888_108.069_CC_Spe  \\\n",
            "0                   5.059911e+06               9.695506e+05   \n",
            "1                   8.319504e+06               1.047507e+06   \n",
            "2                   9.474230e+06               1.156248e+06   \n",
            "3                   5.708948e+06               1.019516e+07   \n",
            "4                   6.124324e+06               1.263953e+06   \n",
            "..                           ...                        ...   \n",
            "175                 4.789807e+07               7.355859e+06   \n",
            "176                 4.511940e+07               6.813359e+06   \n",
            "177                 2.598265e+08               8.338624e+06   \n",
            "178                 2.307037e+07               7.014516e+06   \n",
            "179                 2.050784e+07               2.301169e+06   \n",
            "\n",
            "     RPPI_1.84_109.0531_CC_Spe  ...  RPPI_1.361_368.12193_NM  \\\n",
            "0                 3.393962e+07  ...             3.043215e+06   \n",
            "1                 1.386002e+07  ...             3.976165e+06   \n",
            "2                 1.025721e+07  ...             4.179963e+06   \n",
            "3                 2.285504e+07  ...             6.667801e+06   \n",
            "4                 1.708293e+07  ...             4.027344e+06   \n",
            "..                         ...  ...                      ...   \n",
            "175               1.837977e+07  ...             6.287672e+09   \n",
            "176               1.319361e+07  ...             5.615793e+09   \n",
            "177               1.827340e+07  ...             5.342633e+08   \n",
            "178               1.781402e+07  ...             1.208790e+09   \n",
            "179               1.267557e+07  ...             1.556169e+09   \n",
            "\n",
            "     RPPI_7.68_372.1396_ECG_Spe  RPPI_9.049_377.16891_NRT_Spe  \\\n",
            "0                  2.275592e+06                  3.864005e+06   \n",
            "1                  1.240111e+06                  2.690036e+06   \n",
            "2                  1.205896e+06                  2.878265e+06   \n",
            "3                  2.086369e+06                  2.667389e+06   \n",
            "4                  1.404823e+06                  4.195356e+06   \n",
            "..                          ...                           ...   \n",
            "175                3.391517e+06                  5.841990e+06   \n",
            "176                4.899811e+06                  1.295804e+07   \n",
            "177                4.335911e+06                  8.672925e+06   \n",
            "178                7.527070e+05                  2.866824e+06   \n",
            "179                3.427509e+06                  7.749134e+06   \n",
            "\n",
            "     RPNI_11.873_398.19464_CC+HTP_Spe  RPNI_12.469_410.19456_CC+HTP_Spe  \\\n",
            "0                        1.824716e+06                      7.293626e+05   \n",
            "1                        1.120116e+06                      1.035064e+06   \n",
            "2                        1.074099e+06                      1.069337e+06   \n",
            "3                        3.233640e+06                      6.353487e+05   \n",
            "4                        4.498178e+06                      1.144795e+06   \n",
            "..                                ...                               ...   \n",
            "175                      5.855890e+06                      1.534786e+06   \n",
            "176                      5.769789e+06                      1.391463e+06   \n",
            "177                      3.926159e+06                      3.139884e+06   \n",
            "178                      3.264363e+06                      1.363936e+06   \n",
            "179                      2.497828e+06                      1.333291e+06   \n",
            "\n",
            "     RPNI_11.951_438.22645_HTP_Spe  RPPI_10.516_450.23687_CC+HTP_Spe  \\\n",
            "0                     3.293549e+07                      3.683622e+06   \n",
            "1                     3.405981e+07                      1.121277e+07   \n",
            "2                     2.376208e+07                      2.789782e+06   \n",
            "3                     1.433508e+06                      2.790734e+06   \n",
            "4                     1.679113e+06                      6.866587e+06   \n",
            "..                             ...                               ...   \n",
            "175                   3.878424e+06                      5.436291e+06   \n",
            "176                   4.693385e+06                      8.935678e+06   \n",
            "177                   5.088860e+06                      3.818523e+06   \n",
            "178                   4.173694e+06                      2.405461e+06   \n",
            "179                   3.460630e+06                      2.417176e+06   \n",
            "\n",
            "     RPNI_9.509_480.20039_HTP_Spe  RPPI_1.196_203.11582_OT_Spe  \\\n",
            "0                    2.778891e+06                 1.013052e+09   \n",
            "1                    5.515243e+05                 7.717111e+08   \n",
            "2                    1.034017e+06                 4.227555e+08   \n",
            "3                    7.093404e+06                 4.512504e+09   \n",
            "4                    7.811348e+06                 3.404038e+09   \n",
            "..                            ...                          ...   \n",
            "175                  6.860263e+06                 9.103543e+09   \n",
            "176                  6.561117e+06                 2.255253e+10   \n",
            "177                  4.085621e+06                 1.274333e+10   \n",
            "178                  4.271588e+06                 5.989435e+09   \n",
            "179                  4.628034e+06                 6.002952e+09   \n",
            "\n",
            "     HIPI_1.444_230.113_ECG_Spe  \n",
            "0                  6.221906e+05  \n",
            "1                  3.943595e+05  \n",
            "2                  6.826526e+05  \n",
            "3                  1.058161e+06  \n",
            "4                  1.066202e+06  \n",
            "..                          ...  \n",
            "175                5.459510e+05  \n",
            "176                7.367195e+05  \n",
            "177                1.390944e+06  \n",
            "178                1.177826e+06  \n",
            "179                1.167959e+06  \n",
            "\n",
            "[180 rows x 209 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I8GLZiXsR5Am",
        "outputId": "eab55455-5649-4e0b-9712-c02eafd7a450"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(180, 208)\n",
            "(180,)\n",
            "X_train.shape: (126, 208)\n",
            "y_train.shape: (126,)\n",
            "X_test.shape: (54, 208)\n",
            "y_test.shape: (54,)\n"
          ]
        }
      ],
      "source": [
        "# Encoding the categorical column into numerical values\n",
        "label_dict = {'NU': 0, 'CC': 1, 'ECG': 2, 'HTP': 3, 'NRT': 4, 'OT': 5}\n",
        "df['Group_encoded'] = df['Group'].map(label_dict)\n",
        "\n",
        "# Display the first and last few rows of the DataFrame\n",
        "df.head()\n",
        "df.tail()\n",
        "\n",
        "# Split the data into features (X) and target variable (y)\n",
        "X = df.drop(['Group', 'Group_encoded'], axis=1)\n",
        "y = df['Group_encoded']\n",
        "\n",
        "# Display the features and target variable\n",
        "X.head()\n",
        "y.head()\n",
        "\n",
        "# Display the shape of the dataset\n",
        "print(X.shape)\n",
        "print(y.shape)\n",
        "\n",
        "# Split the data into training and testing sets in a stratified way\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, shuffle=True, random_state=42, stratify=y)\n",
        "\n",
        "# Display the shapes of the splitted data\n",
        "print(f'X_train.shape: {X_train.shape}')\n",
        "print(f'y_train.shape: {y_train.shape}')\n",
        "print(f'X_test.shape: {X_test.shape}')\n",
        "print(f'y_test.shape: {y_test.shape}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "id": "ZlxpJgFXR5D1"
      },
      "outputs": [],
      "source": [
        "# Initializing Classifiers\n",
        "rf_model = RandomForestClassifier(random_state=42)\n",
        "dt_model = DecisionTreeClassifier(random_state=42)\n",
        "gb_model = GradientBoostingClassifier()\n",
        "knn_model = KNeighborsClassifier()\n",
        "svm_model = SVC()\n",
        "mlp_model = MLPClassifier()\n",
        "\n",
        "# Building the pipelines\n",
        "knn_model_std = Pipeline([('std', StandardScaler()), ('knn_model', knn_model)])\n",
        "svm_model_std = Pipeline([('std', StandardScaler()), ('svm_model', svm_model)])\n",
        "mlp_model_std = Pipeline([('std', StandardScaler()), ('mlp_model', mlp_model)])\n",
        "\n",
        "# Setting up the parameter grids\n",
        "\n",
        "param_grid_rf = {\n",
        "    'n_estimators': [50, 100, 200, 300], # NL2, NL5 Optimised\n",
        "    'max_depth': [None, 2, 3, 5], # NL2 Optimised\n",
        "    'min_samples_split': [2, 3, 5, 10], # Optimised\n",
        "    'min_samples_leaf': [1, 2, 3, 5], # NL5 Optimised\n",
        "    'max_leaf_nodes': [None, 10, 20, 30]} # Optimised\n",
        "\n",
        "param_grid_dt = {\n",
        "    'max_depth': [5, 10, 20, 30], # NL2, NL4 Optimised\n",
        "    'min_samples_split': [2, 3, 5, 10, 15], # Optimised\n",
        "    'min_samples_leaf': [1, 2, 3, 5], # NL4 Optimised\n",
        "    'max_leaf_nodes': [None, 10, 20, 30, 40]}\n",
        "\n",
        "param_grid_gb = {\n",
        "    'learning_rate': [0.01, 0.1, 0.2, 0.4, 0.8], # in NL5\n",
        "    'n_estimators': [50, 100, 150, 200, 300], # in NL5\n",
        "    'subsample': [0.2, 0.4, 0.6, 0.8], # in NL5\n",
        "    'max_depth': [2, 3, 5, 10], # in 3S, NL5\n",
        "    'min_samples_leaf': [4, 6, 8, 10]}\n",
        "\n",
        "param_grid_knn = {\n",
        "    'knn_model__n_neighbors': np.arange(1, 10), # in 20S\n",
        "    'knn_model__weights': ['uniform', 'distance'],\n",
        "    'knn_model__leaf_size': [5, 10, 20, 40],\n",
        "    'knn_model__p': [1, 2],\n",
        "    'knn_model__metric': ['euclidean', 'manhattan']}\n",
        "\n",
        "param_grid_svm = [{\n",
        "    'svm_model__kernel': ['rbf'],\n",
        "    'svm_model__C': np.power(10., np.arange(-5, 5)),\n",
        "    'svm_model__gamma': np.power(10., np.arange(-6, 0))},\n",
        "    {'svm_model__kernel': ['linear'],\n",
        "    'svm_model__C': np.power(10., np.arange(-5, 5))}]\n",
        "\n",
        "param_grid_mlp = {\n",
        "    'mlp_model__hidden_layer_sizes': [(50,), (100,), (150,), (50, 50), (100, 50), (100, 100)],\n",
        "    'mlp_model__alpha': [0.00001, 0.0001, 0.001, 0.01, 0.1],\n",
        "    'mlp_model__learning_rate_init': [0.0001, 0.001, 0.01, 0.1],\n",
        "    'mlp_model__max_iter': [100, 200, 300, 500, 1000],\n",
        "    'mlp_model__batch_size': [16, 32, 64, 128]}\n",
        "\n",
        "# Create a list of classifiers, corresponding parameter grids and classifier short name\n",
        "classifiers = [rf_model, dt_model, gb_model, knn_model_std, svm_model_std, mlp_model_std]\n",
        "param_grids = [param_grid_rf, param_grid_dt, param_grid_gb, param_grid_knn, param_grid_svm, param_grid_mlp]\n",
        "name = ['RForest', 'DTree', 'GradientBoosting', 'KNN', 'SVM', 'MLP']"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.regularizers import l1, l2\n",
        "\n",
        "# Inside your create_model function\n",
        "def create_model(num_layers=1, units=64, activation='relu', kernel_regularizer=None, activity_regularizer=None, dropout_rate=0.3, learning_rate=0.001):\n",
        "    model = Sequential()\n",
        "\n",
        "    # Add input layer\n",
        "    model.add(Dense(units, input_dim=X_train.shape[1], activation=activation, kernel_regularizer=kernel_regularizer, activity_regularizer=activity_regularizer))\n",
        "\n",
        "    # Add hidden layers\n",
        "    for _ in range(num_layers - 1):\n",
        "        model.add(Dense(units, activation=activation, kernel_regularizer=kernel_regularizer, activity_regularizer=activity_regularizer))\n",
        "        model.add(tf.keras.layers.Dropout(dropout_rate))\n",
        "\n",
        "    # Output layer\n",
        "    model.add(Dense(len(np.unique(y_train)), activation='softmax'))\n",
        "\n",
        "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# Create KerasClassifier\n",
        "ann_model = KerasClassifier(build_fn=create_model, epochs=10, batch_size=32, verbose=0)\n",
        "\n",
        "# Building the pipelines\n",
        "ann_model_std = Pipeline([('std', StandardScaler()), ('ann_model', ann_model)])\n",
        "\n",
        "param_grid_ann = {\n",
        "    'ann_model__num_layers': [1, 2],\n",
        "    'ann_model__units': [32, 64, 128],\n",
        "    'ann_model__activation': ['tanh', 'relu'],\n",
        "    'ann_model__kernel_regularizer': [None, 'l1', 'l2'],  # Regularization for weights\n",
        "    'ann_model__activity_regularizer': [None, 'l1', 'l2'],  # Regularization for bias\n",
        "    'ann_model__dropout_rate': [0.2, 0.3, 0.4, 0.5, 0.6],\n",
        "    'ann_model__learning_rate': [0.1, 0.01, 0.001, 0.0001],\n",
        "    'ann_model__batch_size': [8, 16, 32], # can also remove, if yes add into model - epochs=50, batch_size=8\n",
        "    'mlp_model__epochs': [50, 100, 150]} # can also remove, if yes add into model - epochs=50, batch_size=8\n",
        "\n",
        "# Create a list of classifiers, corresponding parameter grids and classifier short name\n",
        "classifiers1 = [ann_model_std]\n",
        "param_grids1 = [param_grid_ann]\n",
        "name1 = ['MLP']\n"
      ],
      "metadata": {
        "id": "-KfyjIzONQ70"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from keras.layers import Dense\n",
        "from keras.models import Sequential\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(128, activation='relu', input_dim=2))\n",
        "model.add(Dense(4, activation='softmax'))\n",
        "model.compile(optimizer='adam', loss=' categorical_crossentropy', metrics=['accuracy'])\n",
        "model.summary()\n",
        "\n",
        "hist = model.fit(x, to_categorical(y), epochs=40, batch_size=10, validation_split=0.2)\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "y_predicted = model.predict(x_test)\n",
        "mat = confusion_matrix(y_test.argmax(axis=1), y_predicted.argmax(axis=1))\n",
        "\n",
        "sns.heatmap(mat, square=True, annot=True, fmt='d', cbar=False, cmap='Blues',\n",
        "            xticklabels=faces.target_names,\n",
        "            yticklabels=faces.target_names)\n",
        "\n",
        "plt.xlabel('Predicted label')\n",
        "plt.ylabel('Actual label')"
      ],
      "metadata": {
        "id": "WQPR_c6DTDXO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# multi-class classification with Keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from scikeras.wrappers import KerasClassifier\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "# define baseline model\n",
        "def baseline_model():\n",
        " model = Sequential()\n",
        " model.add(Dense(64, input_dim=4, activation='relu'))\n",
        " model.add(Dense(128, activation = 'relu'))\n",
        " model.add(Dropout(0.2))\n",
        " model.add(Dense(6, activation='softmax'))\n",
        " model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        " return model\n",
        "\n",
        "ann_model = KerasClassifier(model=baseline_model, epochs=200, batch_size=5, verbose=0)\n",
        "\n",
        "param_grid_ann = {\n",
        "    } # can also remove, if yes add into model - epochs=50, batch_size=8\n",
        "\n",
        "# Create a list of classifiers, corresponding parameter grids and classifier short name\n",
        "classifiers1 = [ann_model_std]\n",
        "param_grids1 = [param_grid_ann]\n",
        "name1 = ['MLP']\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 383
        },
        "id": "qtLMX7r0VEjw",
        "outputId": "54f3d79b-190b-4c44-ff6d-788932478ca8"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'scikeras'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-6658079824ba>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDense\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mscikeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrappers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mKerasClassifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mto_categorical\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'scikeras'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VG5pKM06R5Jg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2bfc14ab-2d54-4a20-e50f-674638daf7b4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------------- \n",
            "\n",
            "Algorithm: MLP\n",
            "    Inner loop:\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/scikeras/wrappers.py:915: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
            "  X, y = self._initialize(X, y)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "        Best ACC (avg. of inner test folds) 78.00%\n",
            "        Best parameters: {}\n",
            "        ACC (on outer test fold) 80.77%\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
          ]
        }
      ],
      "source": [
        "# Setting up GridSearchCV objects\n",
        "\n",
        "gridcvs = {}\n",
        "inner_cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=1)\n",
        "\n",
        "for model, param_grid, name in zip(classifiers1, param_grids1, name1):\n",
        "    gcv = GridSearchCV(estimator=model,\n",
        "                       param_grid=param_grid,\n",
        "                       scoring='accuracy',\n",
        "                       cv=inner_cv,\n",
        "                       n_jobs=-1,\n",
        "                       verbose=1,\n",
        "                       refit=True)\n",
        "    gridcvs[name] = gcv\n",
        "\n",
        "# Outer cross-validation loop\n",
        "outer_cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=1)\n",
        "\n",
        "for name, gs_est in sorted(gridcvs.items()):\n",
        "    print(50 * '-', '\\n')\n",
        "    print(f'Algorithm: {name}')\n",
        "    print('    Inner loop:')\n",
        "\n",
        "    # Inner cross-validation loop\n",
        "    for i, (train_index, test_index) in enumerate(outer_cv.split(X_train, y_train), 1):\n",
        "        X_train_inner, X_test_inner = X_train.iloc[train_index], X_train.iloc[test_index]\n",
        "        y_train_inner, y_test_inner = y_train.iloc[train_index], y_train.iloc[test_index]\n",
        "\n",
        "        gs_est.fit(X_train_inner, y_train_inner)\n",
        "\n",
        "        # Assuming `gs_est.best_params_` and `gs_est.best_score_` are accessible\n",
        "        print(f'\\n        Best ACC (avg. of inner test folds) {gs_est.best_score_ * 100:.2f}%')\n",
        "        print(f'        Best parameters: {gs_est.best_params_}')\n",
        "\n",
        "        # Assuming you have a function or code to calculate ACC for the outer test fold\n",
        "        acc_outer = gs_est.score(X_test_inner, y_test_inner)\n",
        "        print(f'        ACC (on outer test fold) {acc_outer * 100:.2f}%')\n",
        "\n",
        "    # Outer cross-validation loop\n",
        "    nested_scores = cross_val_score(gs_est, X_train, y_train, cv=outer_cv, scoring='accuracy')\n",
        "\n",
        "    print('\\n    Outer Loop:')\n",
        "    for i, score in enumerate(nested_scores, 1):\n",
        "        print(f'        ACC {score * 100:.2f}%')\n",
        "\n",
        "    print(f'\\n{name} | outer ACC {nested_scores.mean() * 100:.2f}% +/- {nested_scores.std() * 100:.2f}')\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N8ZoanMzR5L3"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VzwTE6_JR5k1"
      },
      "source": [
        "### Version of the all the library being used in the project"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3gfdmxXULgVe"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "import pkg_resources\n",
        "\n",
        "packages_to_check = ['scikit-learn',\n",
        "                     'tensorflow',\n",
        "                     'pandas',\n",
        "                     'numpy',\n",
        "                     'openpyxl',\n",
        "                     'matPlotlib',\n",
        "                     'matPlotlib',\n",
        "                     'joblib',\n",
        "                     'scikeras',\n",
        "                     'mlxtend']\n",
        "\n",
        "# Print the Python version\n",
        "python_version = f\"{sys.version_info.major}.{sys.version_info.minor}.{sys.version_info.micro}\"\n",
        "print(f\"Python version: {python_version}\")\n",
        "\n",
        "# Print the versions\n",
        "for package in packages_to_check:\n",
        "    version = pkg_resources.get_distribution(package).version\n",
        "    print(f\"{package.capitalize()} version: {version}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yIEXOatvLrUD"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNUew/UUOWTDpfG1CrOxO6t",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}